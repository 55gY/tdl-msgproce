package main

import (
	"context"
	"encoding/json"
	"fmt"
	"os"
	"sync"
	"time"

	"github.com/gotd/td/telegram/peers"
	"github.com/iyear/tdl/core/storage"
	"github.com/iyear/tdl/core/util/tutil"
	"go.uber.org/zap"
)

// JSONMessage JSONæ–‡ä»¶ä¸­çš„æ¶ˆæ¯æ ¼å¼
type JSONMessage struct {
	ID   int    `json:"id"`
	Type string `json:"type"`
}

// JSONExport Telegramå¯¼å‡ºçš„JSONæ ¼å¼
type JSONExport struct {
	ID       int64         `json:"id"`
	Messages []JSONMessage `json:"messages"`
}

// VerifyResult éªŒè¯ç»“æœ
type VerifyResult struct {
	TotalMessages   int
	ValidMessages   int
	InvalidMessages int
	InvalidIDs      []int
	FirstErrorIndex int
	FirstErrorID    int
	ErrorMessage    string
}

// VerifyJSONMessages éªŒè¯JSONæ–‡ä»¶ä¸­çš„æ¶ˆæ¯IDæ˜¯å¦æœ‰æ•ˆ
func (p *MessageProcessor) VerifyJSONMessages(ctx context.Context, jsonFile string) (*VerifyResult, error) {
	p.ext.Log().Info("å¼€å§‹éªŒè¯JSONæ–‡ä»¶", zap.String("file", jsonFile))

	// è¯»å–JSONæ–‡ä»¶
	data, err := os.ReadFile(jsonFile)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// è§£æJSON
	var export JSONExport
	if err := json.Unmarshal(data, &export); err != nil {
		return nil, fmt.Errorf("è§£æJSONå¤±è´¥: %w", err)
	}

	if export.ID == 0 {
		return nil, fmt.Errorf("æ— æ³•ä»JSONä¸­è·å–é¢‘é“/ç¾¤ç»„ID")
	}

	// è¿‡æ»¤å‡ºç±»å‹ä¸ºmessageçš„æ¶ˆæ¯
	var messageIDs []int
	for _, msg := range export.Messages {
		if msg.Type == "message" && msg.ID > 0 {
			messageIDs = append(messageIDs, msg.ID)
		}
	}

	if len(messageIDs) == 0 {
		return nil, fmt.Errorf("JSONä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ¶ˆæ¯")
	}

	p.ext.Log().Info("å¼€å§‹éªŒè¯æ¶ˆæ¯", 
		zap.Int64("channelID", export.ID),
		zap.Int("totalMessages", len(messageIDs)))

	result := &VerifyResult{
		TotalMessages:   len(messageIDs),
		FirstErrorIndex: -1,
	}

	// è·å–é¢‘é“/ç¾¤ç»„ä¿¡æ¯
	client := p.ext.Client()
	api := client.API()
	kvd := newMemoryStorage()
	manager := peers.Options{Storage: storage.NewPeers(kvd)}.Build(api)

	peer, err := tutil.GetInputPeer(ctx, manager, fmt.Sprintf("%d", export.ID))
	if err != nil {
		return nil, fmt.Errorf("è·å–é¢‘é“/ç¾¤ç»„ä¿¡æ¯å¤±è´¥: %w", err)
	}

	p.ext.Log().Info("é¢‘é“/ç¾¤ç»„ä¿¡æ¯", 
		zap.Int64("id", peer.ID()),
		zap.String("name", peer.VisibleName()))

	// ä½¿ç”¨20çº¿ç¨‹å¹¶å‘éªŒè¯æ¶ˆæ¯
	const numWorkers = 20
	jobs := make(chan struct{
		index int
		msgID int
	}, len(messageIDs))
	results := make(chan struct{
		index      int
		msgID      int
		isValid    bool
		errMessage string
	}, len(messageIDs))

	// å¯åŠ¨å·¥ä½œåç¨‹
	var wg sync.WaitGroup
	for i := 0; i < numWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for job := range jobs {
				// å°è¯•è·å–æ¶ˆæ¯
				msg, err := tutil.GetSingleMessage(ctx, api, peer.InputPeer(), job.msgID)
				if err != nil {
					results <- struct {
						index      int
						msgID      int
						isValid    bool
						errMessage string
					}{job.index, job.msgID, false, err.Error()}
					continue
				}

				// éªŒè¯æ¶ˆæ¯IDæ˜¯å¦åŒ¹é…
				if msg.GetID() != job.msgID {
					results <- struct {
						index      int
						msgID      int
						isValid    bool
						errMessage string
					}{job.index, job.msgID, false, fmt.Sprintf("æ¶ˆæ¯IDä¸åŒ¹é…ï¼ŒæœŸæœ›:%d å®é™…:%d", job.msgID, msg.GetID())}
					continue
				}

				results <- struct {
					index      int
					msgID      int
					isValid    bool
					errMessage string
				}{job.index, job.msgID, true, ""}

				// æ·»åŠ çŸ­æš‚å»¶è¿Ÿé¿å…è§¦å‘é™æµ
				time.Sleep(10 * time.Millisecond)
			}
		}()
	}

	// å‘é€ä»»åŠ¡
	for i, msgID := range messageIDs {
		jobs <- struct {
			index int
			msgID int
		}{i, msgID}
	}
	close(jobs)

	// ç­‰å¾…æ‰€æœ‰å·¥ä½œå®Œæˆ
	go func() {
		wg.Wait()
		close(results)
	}()

	// æ”¶é›†ç»“æœï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰
	processed := 0
	lastProgress := 0
	for res := range results {
		processed++
		
		// æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯10%ï¼‰
		progress := processed * 100 / len(messageIDs)
		if progress >= lastProgress+10 {
			fmt.Printf("éªŒè¯è¿›åº¦: %d%% (%d/%d)\n", progress, processed, len(messageIDs))
			lastProgress = progress
		}

		if !res.isValid {
			result.InvalidMessages++
			result.InvalidIDs = append(result.InvalidIDs, res.msgID)
			
			if result.FirstErrorIndex == -1 || res.index < result.FirstErrorIndex {
				result.FirstErrorIndex = res.index
				result.FirstErrorID = res.msgID
				result.ErrorMessage = res.errMessage
				
				p.ext.Log().Warn("å‘ç°æ— æ•ˆæ¶ˆæ¯", 
					zap.Int("index", res.index),
					zap.Int("messageID", res.msgID),
					zap.String("error", res.errMessage))
			}
		} else {
			result.ValidMessages++
		}
	}

	p.ext.Log().Info("éªŒè¯å®Œæˆ", 
		zap.Int("total", result.TotalMessages),
		zap.Int("valid", result.ValidMessages),
		zap.Int("invalid", result.InvalidMessages))

	return result, nil
}

// CreateCleanedJSON åˆ›å»ºæ¸…ç†åçš„JSONæ–‡ä»¶ï¼ˆç§»é™¤æ— æ•ˆæ¶ˆæ¯ï¼‰
func (p *MessageProcessor) CreateCleanedJSON(originalFile string, outputFile string, invalidIDs []int) error {
	p.ext.Log().Info("åˆ›å»ºæ¸…ç†åçš„JSON", 
		zap.String("input", originalFile),
		zap.String("output", outputFile),
		zap.Int("removeCount", len(invalidIDs)))

	// è¯»å–åŸå§‹JSON
	data, err := os.ReadFile(originalFile)
	if err != nil {
		return fmt.Errorf("è¯»å–æ–‡ä»¶å¤±è´¥: %w", err)
	}

	var export JSONExport
	if err := json.Unmarshal(data, &export); err != nil {
		return fmt.Errorf("è§£æJSONå¤±è´¥: %w", err)
	}

	// åˆ›å»ºæ— æ•ˆIDçš„mapç”¨äºå¿«é€ŸæŸ¥æ‰¾
	invalidMap := make(map[int]bool)
	for _, id := range invalidIDs {
		invalidMap[id] = true
	}

	// è¿‡æ»¤æ¶ˆæ¯
	var cleanedMessages []JSONMessage
	for _, msg := range export.Messages {
		if !invalidMap[msg.ID] {
			cleanedMessages = append(cleanedMessages, msg)
		}
	}

	export.Messages = cleanedMessages

	// å†™å…¥æ–°æ–‡ä»¶
	output, err := json.MarshalIndent(export, "", "  ")
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–JSONå¤±è´¥: %w", err)
	}

	if err := os.WriteFile(outputFile, output, 0644); err != nil {
		return fmt.Errorf("å†™å…¥æ–‡ä»¶å¤±è´¥: %w", err)
	}

	p.ext.Log().Info("æ¸…ç†åçš„JSONå·²ä¿å­˜", 
		zap.String("file", outputFile),
		zap.Int("originalCount", len(export.Messages)+len(invalidIDs)),
		zap.Int("cleanedCount", len(cleanedMessages)))

	return nil
}

// VerifyAndFixJSON éªŒè¯JSONå¹¶åˆ›å»ºä¿®å¤ç‰ˆæœ¬
func (p *MessageProcessor) VerifyAndFixJSON(ctx context.Context, jsonFile string) error {
	fmt.Println("ğŸ” å¼€å§‹éªŒè¯JSONæ–‡ä»¶...")
	
	result, err := p.VerifyJSONMessages(ctx, jsonFile)
	if err != nil {
		return fmt.Errorf("éªŒè¯å¤±è´¥: %w", err)
	}

	// æ‰“å°ç»“æœ
	fmt.Println("\nğŸ“Š éªŒè¯ç»“æœ:")
	fmt.Printf("æ€»æ¶ˆæ¯æ•°: %d\n", result.TotalMessages)
	fmt.Printf("âœ… æœ‰æ•ˆæ¶ˆæ¯: %d (%.1f%%)\n", 
		result.ValidMessages, 
		float64(result.ValidMessages)*100/float64(result.TotalMessages))
	fmt.Printf("âŒ æ— æ•ˆæ¶ˆæ¯: %d (%.1f%%)\n", 
		result.InvalidMessages,
		float64(result.InvalidMessages)*100/float64(result.TotalMessages))

	if result.FirstErrorIndex >= 0 {
		fmt.Printf("\nâš ï¸  ç¬¬ä¸€ä¸ªé”™è¯¯ä½ç½®:\n")
		fmt.Printf("   ç´¢å¼•: %d (ç¬¬%dæ¡æ¶ˆæ¯)\n", result.FirstErrorIndex, result.FirstErrorIndex+1)
		fmt.Printf("   æ¶ˆæ¯ID: %d\n", result.FirstErrorID)
		fmt.Printf("   é”™è¯¯: %s\n", result.ErrorMessage)
	}

	// å¦‚æœæœ‰æ— æ•ˆæ¶ˆæ¯ï¼Œåˆ›å»ºæ¸…ç†ç‰ˆæœ¬
	if result.InvalidMessages > 0 {
		outputFile := jsonFile[:len(jsonFile)-5] + "_cleaned.json"
		fmt.Printf("\nğŸ”§ æ­£åœ¨åˆ›å»ºæ¸…ç†åçš„JSON: %s\n", outputFile)
		
		if err := p.CreateCleanedJSON(jsonFile, outputFile, result.InvalidIDs); err != nil {
			return fmt.Errorf("åˆ›å»ºæ¸…ç†ç‰ˆæœ¬å¤±è´¥: %w", err)
		}

		fmt.Printf("âœ… æ¸…ç†å®Œæˆï¼æ–°æ–‡ä»¶å·²ä¿å­˜\n")
		fmt.Printf("   åŸå§‹æ–‡ä»¶: %s (%dæ¡æ¶ˆæ¯)\n", jsonFile, result.TotalMessages)
		fmt.Printf("   æ¸…ç†æ–‡ä»¶: %s (%dæ¡æ¶ˆæ¯)\n", outputFile, result.ValidMessages)
		fmt.Println("\nğŸ’¡ å»ºè®®ä½¿ç”¨æ¸…ç†åçš„æ–‡ä»¶è¿›è¡Œè½¬å‘")
	} else {
		fmt.Println("\nâœ… æ‰€æœ‰æ¶ˆæ¯éƒ½æœ‰æ•ˆï¼Œæ— éœ€æ¸…ç†ï¼")
	}

	return nil
}
